{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1: Data Scraping and Collection\n",
    "\n",
    "This notebook demonstrates the implementation of the Telegram data scraping pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "numpy.dtype size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mos\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mjson\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpd\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mdatetime\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m datetime\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mplt\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Abenezer\\Desktop\\KAIM Project\\medical-telegram-warehouse\\venv8\\Lib\\site-packages\\pandas\\__init__.py:47\u001b[39m\n\u001b[32m     40\u001b[39m     _module = _err.name\n\u001b[32m     41\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\n\u001b[32m     42\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mC extension: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m_module\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m not built. If you want to import \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     43\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mpandas from the source directory, you may need to run \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     44\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m'\u001b[39m\u001b[33mpython setup.py build_ext\u001b[39m\u001b[33m'\u001b[39m\u001b[33m to build the C extensions first.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     45\u001b[39m     ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m_err\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m47\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_config\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     48\u001b[39m     get_option,\n\u001b[32m     49\u001b[39m     set_option,\n\u001b[32m     50\u001b[39m     reset_option,\n\u001b[32m     51\u001b[39m     describe_option,\n\u001b[32m     52\u001b[39m     option_context,\n\u001b[32m     53\u001b[39m     options,\n\u001b[32m     54\u001b[39m )\n\u001b[32m     56\u001b[39m \u001b[38;5;66;03m# let init-time option registration happen\u001b[39;00m\n\u001b[32m     57\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mconfig_init\u001b[39;00m  \u001b[38;5;66;03m# pyright: ignore[reportUnusedImport] # noqa: F401\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Abenezer\\Desktop\\KAIM Project\\medical-telegram-warehouse\\venv8\\Lib\\site-packages\\pandas\\_config\\__init__.py:19\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[33;03mpandas._config is considered explicitly upstream of everything else in pandas,\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[33;03mshould have no intra-pandas dependencies.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m      6\u001b[39m \u001b[33;03mare initialized.\u001b[39;00m\n\u001b[32m      7\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m      8\u001b[39m __all__ = [\n\u001b[32m      9\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mconfig\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     10\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mdetect_console_encoding\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m     17\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33musing_copy_on_write\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     18\u001b[39m ]\n\u001b[32m---> \u001b[39m\u001b[32m19\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_config\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m config\n\u001b[32m     20\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_config\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m dates  \u001b[38;5;66;03m# pyright: ignore[reportUnusedImport]  # noqa: F401\u001b[39;00m\n\u001b[32m     21\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_config\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mconfig\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     22\u001b[39m     _global_config,\n\u001b[32m     23\u001b[39m     describe_option,\n\u001b[32m   (...)\u001b[39m\u001b[32m     28\u001b[39m     set_option,\n\u001b[32m     29\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Abenezer\\Desktop\\KAIM Project\\medical-telegram-warehouse\\venv8\\Lib\\site-packages\\pandas\\_config\\config.py:68\u001b[39m\n\u001b[32m     58\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtyping\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     59\u001b[39m     TYPE_CHECKING,\n\u001b[32m     60\u001b[39m     Any,\n\u001b[32m   (...)\u001b[39m\u001b[32m     64\u001b[39m     cast,\n\u001b[32m     65\u001b[39m )\n\u001b[32m     66\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mwarnings\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m68\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_typing\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     69\u001b[39m     F,\n\u001b[32m     70\u001b[39m     T,\n\u001b[32m     71\u001b[39m )\n\u001b[32m     72\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutil\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_exceptions\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m find_stack_level\n\u001b[32m     74\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m TYPE_CHECKING:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Abenezer\\Desktop\\KAIM Project\\medical-telegram-warehouse\\venv8\\Lib\\site-packages\\pandas\\_typing.py:163\u001b[39m\n\u001b[32m    157\u001b[39m Frequency = Union[\u001b[38;5;28mstr\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mBaseOffset\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m    158\u001b[39m Axes = ListLike\n\u001b[32m    160\u001b[39m RandomState = Union[\n\u001b[32m    161\u001b[39m     \u001b[38;5;28mint\u001b[39m,\n\u001b[32m    162\u001b[39m     np.ndarray,\n\u001b[32m--> \u001b[39m\u001b[32m163\u001b[39m     \u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrandom\u001b[49m.Generator,\n\u001b[32m    164\u001b[39m     np.random.BitGenerator,\n\u001b[32m    165\u001b[39m     np.random.RandomState,\n\u001b[32m    166\u001b[39m ]\n\u001b[32m    168\u001b[39m \u001b[38;5;66;03m# dtypes\u001b[39;00m\n\u001b[32m    169\u001b[39m NpDtype = Union[\u001b[38;5;28mstr\u001b[39m, np.dtype, type_t[Union[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mcomplex\u001b[39m, \u001b[38;5;28mbool\u001b[39m, \u001b[38;5;28mobject\u001b[39m]]]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Abenezer\\Desktop\\KAIM Project\\medical-telegram-warehouse\\venv8\\Lib\\site-packages\\numpy\\__init__.py:731\u001b[39m, in \u001b[36m__getattr__\u001b[39m\u001b[34m(attr)\u001b[39m\n\u001b[32m      0\u001b[39m <Error retrieving source code with stack_data see ipython/ipython#13598>\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Abenezer\\Desktop\\KAIM Project\\medical-telegram-warehouse\\venv8\\Lib\\site-packages\\numpy\\random\\__init__.py:180\u001b[39m\n\u001b[32m    126\u001b[39m __all__ = [\n\u001b[32m    127\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mbeta\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m    128\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mbinomial\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    176\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mzipf\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m    177\u001b[39m ]\n\u001b[32m    179\u001b[39m \u001b[38;5;66;03m# add these for module-freeze analysis (like PyInstaller)\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m180\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _pickle\n\u001b[32m    181\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _common\n\u001b[32m    182\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _bounded_integers\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Abenezer\\Desktop\\KAIM Project\\medical-telegram-warehouse\\venv8\\Lib\\site-packages\\numpy\\random\\_pickle.py:1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmtrand\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m RandomState\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_philox\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Philox\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_pcg64\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m PCG64, PCG64DXSM\n",
      "\u001b[36mFile \u001b[39m\u001b[32mnumpy\\\\random\\\\mtrand.pyx:1\u001b[39m, in \u001b[36minit numpy.random.mtrand\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mValueError\u001b[39m: numpy.dtype size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Set plotting style\n",
    "plt.style.use('seaborn-v0_8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the directory structure created by the scraper\n",
    "print(\"Data Lake Structure:\")\n",
    "!tree data/raw  # On Windows, you might need to use dir or ls depending on your environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load sample data from the data lake\n",
    "import glob\n",
    "\n",
    "# Find the most recent date folder\n",
    "date_folders = glob.glob('data/raw/telegram_messages/*')\n",
    "if date_folders:\n",
    "    latest_date = max(date_folders, key=os.path.getctime)\n",
    "    print(f\"Latest date folder: {latest_date}\")\n",
    "    \n",
    "    # List JSON files in the latest date folder\n",
    "    json_files = glob.glob(os.path.join(latest_date, '*.json'))\n",
    "    print(f\"JSON files found: {json_files}\")\n",
    "    \n",
    "    if json_files:\n",
    "        # Load the first JSON file as a sample\n",
    "        with open(json_files[0], 'r', encoding='utf-8') as f:\n",
    "            sample_data = json.load(f)\n",
    "        \n",
    "        print(f\"\\nSample data loaded. Number of messages: {len(sample_data)}\")\n",
    "        print(\"\\nFirst message sample:\")\n",
    "        print(json.dumps(sample_data[0], indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show statistics about the scraped data\n",
    "if 'sample_data' in locals():\n",
    "    df = pd.DataFrame(sample_data)\n",
    "    print(\"\\nData Statistics:\")\n",
    "    print(df.describe())\n",
    "    \n",
    "    print(\"\\nChannel Distribution:\")\n",
    "    print(df['channel_name'].value_counts())\n",
    "    \n",
    "    # Plot channel distribution\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    df['channel_name'].value_counts().plot(kind='bar')\n",
    "    plt.title('Distribution of Messages by Channel')\n",
    "    plt.xlabel('Channel')\n",
    "    plt.ylabel('Number of Messages')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the logs\n",
    "import glob\n",
    "\n",
    "log_files = glob.glob('logs/scrape_*.log')\n",
    "if log_files:\n",
    "    latest_log = max(log_files, key=os.path.getctime)\n",
    "    print(f\"\\nContent of the latest log file ({latest_log}):\")\n",
    "    with open(latest_log, 'r', encoding='utf-8') as f:\n",
    "        print(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show image downloads\n",
    "import os\n",
    "\n",
    "image_dirs = [d for d in os.listdir('data/raw/images') if os.path.isdir(os.path.join('data/raw/images', d))]\n",
    "print(f\"Channels with downloaded images: {image_dirs}\")\n",
    "\n",
    "for channel in image_dirs:\n",
    "    images = os.listdir(os.path.join('data/raw/images', channel))\n",
    "    print(f\"{channel}: {len(images)} images downloaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "Task 1 successfully implemented a Telegram scraping pipeline that:\n",
    "1. Extracts messages from specified Ethiopian medical channels\n",
    "2. Downloads associated images\n",
    "3. Stores data in a structured data lake format\n",
    "4. Maintains proper logging\n",
    "\n",
    "The data is stored in a partitioned structure by date and channel, making it suitable for further processing."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv8",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
